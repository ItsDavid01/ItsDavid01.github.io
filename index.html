<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <meta http-equiv="X-UA-Compatible" content="IE=edge" />
    <title>
      Information on accident victims in Barranquilla - Universidad del Norte
    </title>
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <link rel="stylesheet" type="text/css" media="screen" href="styles.css" />
  </head>

  <header>
    <div id="title">
      <h2>Accident victims in Barranquilla</h2>
    </div>

    <div id="title2">
      <h3>Optimization Course - Universidad del norte</h3>
    </div>
  </header>

  <div class="clearfix"></div>

  <body>
    <div id="content1">
      <h1>¡Meet the Team!</h1>

      <div id="teamDesc">
        <ol>
          <li>
            <img class="fotoPersona" src="Fotos/david.jpg" alt="David Meza" />
            <p>David Meza</p>
            <p>Web Developer</p>
          </li>
          <li>
            <img
              class="fotoPersona"
              src="Fotos/andres.jpeg"
              alt="Andres Evertsz"
            />
            <p>Andres Evertsz</p>
            <p>Data Analist</p>
          </li>
          <li>
            <img
              src="Fotos/foto.png"
              alt="Cristian Berrio"
              class="fotoPersona"
            />
            <p>Cristian Berrio</p>
            <p>Creative investigator and Developer</p>
          </li>
          <li>
            <img
              src="Fotos/sebastian.jpg"
              alt="Sebastian Guzman"
              class="fotoPersona"
            />
            <p>Sebastian Guzman</p>
            <p>Tester</p>
          </li>
        </ol>
      </div>
    </div>

    <div class="clearfix"></div>

    <div id="content2">
      <h1 class="content2parr" , id="origin_database">Our selected Dataset</h1>
      <h3 class="content2parr">
        Information on accident victims in Barranquilla (from DatosAbiertos)
      </h3>

      <div class="dataset">
        <img
          src="Fotos/Dataset.png"
          alt="Celdas del dataset seleccionado"
          class="fotoDF"
        />
      </div>

      <div class="descripcion">
        <h2 class="title_desc">
          Explanation from our Database and brief visualization of the data
        </h2>

        <div class="parrafoDesc">
          <p>
            The dataset "Accidentalidad en Barranquilla - víctimas" (Accidents
            in Barranquilla - victims) from datos.gov.co is crucial for
            addressing public safety concerns, transportation planning, policy
            formulation, research endeavors, community awareness, and resource
            allocation. By providing comprehensive information about accident
            victims in Barranquilla, Colombia, this dataset serves as a vital
            tool for understanding the frequency, nature, and locations of
            accidents, therefore enabling targeted interventions to reduce
            accidents and associated harm.
          </p>
        </div>

        <div class="parrafoDesc">
          <p>
            Analysis of the data facilitates insights into transportation
            patterns, infrastructure deficiencies, and factors contributing to
            accidents, informing the development and evaluation of effective
            policies aimed at enhancing road safety. Moreover, making this data
            publicly available raises community awareness about the importance
            of road safety and encourages safer behaviors while traveling.
          </p>
        </div>

        <div class="parrafoDesc">
          <p>
            It's important to mention that with this project We could also
            identify and pinpoint high-risk areas, efficiently allocate
            resources for their prevention, and plan prevention strategies
            accordingly.
          </p>
        </div>
        <div class="parrafoDesc">
          <p>
            The statistical insights derived from the dataset analysis reveal
            notable patterns regarding accident victimization in Barranquilla.
            Fluctuations in the quantity of victims over time suggest potential
            seasonal variations in accident rates, while the distribution of
            victims across different severity levels and types of accidents
            underscores the need for targeted interventions and safety measures.
            Disparities in victim distribution by gender highlight demographic
            considerations for safety initiatives, while identifying age groups
            most affected by accidents offers valuable guidance for tailored
            educational programs and preventive measures. Overall, these
            insights provide crucial information for policymakers and community
            stakeholders to formulate effective strategies aimed at improving
            road safety and reducing the number of accident victims in
            Barranquilla.
          </p>
        </div>

        <div id="fotosDesc">
          <img
            src="Fotos/VictimasPorSexo.png"
            alt="Numero de Victimas Por Sexo"
            class="foto_desc"
          />
          <img
            src="Fotos/VictimasPorClase.png"
            alt="VictimasPorClase"
            class="foto_desc"
          />
          <img
            src="Fotos/VictimasPorGravedad.png"
            alt="VictimasPorClase"
            class="foto_desc"
          />
          <img
            src="Fotos/VictimasPorMes.png"
            alt="VictimasPorClase"
            class="foto_desc"
          />
        </div>
      </div>
    </div>

    <div class="clearfix"></div>

    <div id="content3">
      <div class="descripcion">
        <h1 class="title_desc">Our initial model selection</h1>
        <div class="parrafoDesc">
          <p>
            Looking at the nature of the data and analyzing the information
            within it, we have come to the initial conclusion that with this
            data, we might be able to predict whether a person survives a car
            accident or just gets injured but stays alive.
          </p>
        </div>
        <div class="parrafoDesc">
          <p>
            We have decided to use this condition as our model's output, and for
            the inputs we have decided to take into consideration several
            aspects of the victim of the car accident, as well as some
            conditions regarding the accident itself.
          </p>
        </div>
        <div class="parrafoDesc">
          <p>The inputs of our model will be the following</p>
          <ul class="lista">
            <li class="item_lista">
              <strong>CONDICION_VICTIMA:</strong> which describes, as stated,
              the victim’s role in the accident, for example, was our victim a
              pedestrian? Maybe a motor biker, maybe the driver of one of the
              vehicles involved in the accident. Etc.,
            </li>
            <li class="item_lista">
              <strong>CLASE_ACCIDENTE:</strong> which describes, as stated in
              the name, what happened exactly in the accident, a car crash?
              Someone getting ran over? Etc.,
            </li>
            <li class="item_lista">
              <strong>SEXO_VICTIMA:</strong> which describes the victim’s
              gender, male or female.
            </li>
            <li class="item_lista">
              <strong>EDAD_VICTIMA:</strong> which describes the age of the
              victim.
            </li>
          </ul>
        </div>
        <div class="parrafoDesc">
          <p>
            Our desired output will be GRAVEDAD_ACCIDENTE, which can take two
            different values HERIDO (injured, wounded), MUERTO (dead).
          </p>
        </div>
        <div class="parrafoDesc">
          <p>
            Our general objective is to determine, whether or not, these inputs
            are sufficient enough to train a machine learning model and, most
            importantly, predict with certain level of error, out desired
            output.
          </p>
        </div>
        <div class="parrafoDesc">
          <p>
            We have chosen RandomForestClassifier as out first model selection,
            because at first we can see that we are trying to predict a binary
            categorical variable which can take exactly two cases (death,
            wounded), this is the task of a classifier.
          </p>
        </div>
        <div class="parrafoDesc">
          <p>
            Second but not least important is because the data itself is
            umbalanced, roughly 2% of the accidents end up on death and the vast
            majority of accidents come from crashing (choques). To fix this
            umbalance, we use the Ensemble type model RandomForestClassifier,
            which is specially optimal for umbalanced classes. As another layer
            of protection we also specify a parameter called
            <strong>class_weight="balanced"</strong>
          </p>
        </div>
        <div class="parrafoDesc">
          <p>
            This parameter inverts the class weights in order to give more
            importance to the minority class, which is death cases and is what
            interests us the most.
          </p>
        </div>
        <div class="parrafoDesc">
          <p>
            As for the inputs of our model, since we have both discrete and
            continuous variables we have decided to encode our non-numeric
            variables using the One-Hot_Encoding technique, which creates a
            column for each unique value our categorical variable can take and
            sets 1 to the corresponding column value and 0 for the others. We
            have also used a label enconding for out output column to transform
            the values HERIDO and MUERTO as 0 and 1 respectively
          </p>
        </div>
        <div class="parrafoDesc">
          <p>
            With this technique we have all our inputs as numerical variables
            and we are good to proceed with training the model.
          </p>
        </div>
        <div class="parrafoDesc">
          <p>
            It is important to mention that we have also used a train test
            split, using, initially, 30% of the data for testing.
          </p>
        </div>
        <div class="parrafoDesc">
          <p>
            <strong
              >The following image is a representation of some of the
              dataframe's columns with the One-Hot_Encoding technique
            </strong>
          </p>
        </div>
        <div class="dataset">
          <img
            src="Fotos/OneHotEncodedDataframe.png"
            alt="Algunas celdas del dataset arreglado"
          />
        </div>
        <div class="parrafoDesc">
          <p>
            Before training this model we had to clean our dataframe, since
            there was a small amount of rows (less than 200) with unexplicably
            high and unrealistic age values like 2024 or values above 100 which
            we believe to be not so probable to happen in our context, or with
            no especified gender. Hence the reduction in the amount of rows from
            our <a href="#origin_database">original database</a>
          </p>
        </div>
        <div class="parrafoDesc">
          <p>
            It is important to say that, initially there was a
            "another/not-especified" value for the columns "CONDICION_VICTIMA"
            and "CLASE_ACCIDENTE" and there were a few rows that made use of
            this values, but since the amount was too small and the parameters
            associated with these inputs showed to be not so significant when
            visualizing the coefficients of the model, we decided it'd be best
            to take them out of our final dataframe
          </p>
        </div>
        <div class="parrafoDesc">
          <p>
            The following image is the command used to delete these undesired
            rows we had previously mentioned
          </p>
        </div>
        <div class="dataset">
          <img
            src="Fotos/cleaningCommand.png"
            alt="Comando para quitar filas no deseadas"
          />
        </div>
        <div class="parrafoDesc">
          <p>
            We will check each of the four main matrics to compare the results
            of our model. For that we have decided to run our models several
            times, obtaining a distribution of metric values we will later plot
            for easier analysis
            <strong
              >To obtain the following graphics we ran our model 25 times and
              took one sample out to visualize its confusion matrix, for a
              better understanding of the amount of false or true
              positives/negatives</strong
            >
          </p>
        </div>
        <div class="parrafoDesc">
          <p>
            Here is the confusion matrix of one of the 25 runs, showing us the
            proportion of true or false negative/positives
          </p>
        </div>
        <div class="dataset">
          <img
            src="Fotos/bad_cm_norNorm.png"
            alt="Matriz de confusion del modelo 1"
          />
          <img
            src="Fotos/bad_cm_Norm.png"
            alt="matriz de confusion normalizada del modelo 1"
          />
        </div>
        <div class="parrafoDesc">
          <p>
            By looking at this one run, we can see that our model is pretty good
            at predicting the mayority class, which is "wounded" and stands for
            0 in our model, but is not doing good at predicting the minority
            class
          </p>
        </div>
        <div class="parrafoDesc">
          <p>
            <strong
              >In the following graphics we will see the distribution of scores
              for all 25 runs
            </strong>
          </p>
        </div>
        <div class="dataset">
          <img src="Fotos/bad_acc_scores.png" alt="accuracy del modelo 1" />
          <img src="Fotos/bac_rec_scores.png" alt="recall del modelo 1" />
        </div>
        <div class="dataset">
          <img src="Fotos/bad_f1_scores.png" alt="f1 del modelo 1" />
          <img src="Fotos/bad_pre_scores.png" alt="precision del modelo 1" />
        </div>
      </div>
    </div>

    <div class="clearfix"></div>

    <div id="content4">
      <div class="descripcion">
        <h1 class="title_desc">
          An improvement to our initial model selection
        </h1>
        <div class="parrafoDesc">
          <p>
            We have decided to use a different strategy to correct our data
            imbalance and went for over or under-sampling techniques
          </p>
        </div>

        <div class="parrafoDesc">
          <p>
            These techniques help balance the data through artificially creating
            more samples of the minority class until it equals the mayority one
            (oversampling) or by carefully deducting samples from our mayority
            class to match the amount of samples of our rhe minority one
          </p>
        </div>
        <div class="parrafoDesc">
          <p>
            There are, of course, advantages and disadvantages to the use of
            synthetic generation or deduction of data
          </p>
          <ul class="lista">
            <li class="item_lista">
              <strong>Oversampling:</strong> may lead to overfitting, especially
              if the minority class is oversampled excessively
            </li>
            <li class="item_lista">
              By adding more instances to the dataset,
              <strong>oversampling</strong> increases the size of the dataset,
              which can lead to longer training times and higher computational
              costs.
            </li>
            <li class="item_lista">
              <strong>Oversampling:</strong> helps balance the dataset, which
              can prevent the model from being biased towards the majority
              class.
            </li>
            <li class="item_lista">
              By increasing the number of instances in the minority class
              <strong>EDAD_VICTIMA:</strong> helps the model learn the
              characteristics of the minority class better
            </li>
            <li>
              <strong>Undersampling</strong> may come with an excessive loss of
              information from our mayority class
            </li>
          </ul>
        </div>
        <div class="parrafoDesc">
          <p>
            We have chosen to oversample out minority class because we are more
            concerned about the information loss that comes from undersampling,
            and since the minority class represents roughly 2% of the total
            data, our training data would be too small to be useful in
            generalization
          </p>
        </div>
        <div class="parrafoDesc">
          <p>
            From all the oversampling techniques, we have chonse to use SMOTE,
            since we believe its best to use a sophisticated algorithm than
            using a random Oversampler
          </p>
        </div>
        <div class="dataset">
          <img id=smote src="/Fotos/Smote.png" alt="Smote" />
        </div>
        <div class="parrafoDesc">
          <p>
            As for our model, we have decided to use a Regression Model, but for
            our classification problem we are exclusively using a Logistic
            Regression Model. Since our classes are now balanced thanks to
            SMOTE, we should be able to have decent predicitions using this
            model
          </p>
        <div class="parrafoDesc">
          <p>
            We will check each of the four main matrics to compare the results
            of our model. For that we have decided to run our models several
            times just like the initial model, obtaining a distribution of metric values we will later plot
            for easier analysis
            <strong
              >To obtain the following graphics we ran our model 100 times and
              took one sample out to visualize its confusion matrix, for a
              better understanding of the amount of false or true
              positives/negatives</strong>
          </p>
        </div>
        <div class="parrafoDesc">
          <p>
            Here is the confusion matrix of one of the 100 runs, showing us the
            proportion of true or false negative/positives
          </p>
        </div>
        <div class="dataset">
          <img
            src="Fotos/bgood_cm_Norm.png"
            alt="Matriz de confusion del modelo 2">
        </div>
        <div class="parrafoDesc">
          <p>
            By looking at this one run, we can see, we have sacrified some predictions of our 
            mayority class, but we have gained a much better prediction of our minority class, 
            which was our initial challenge with this dataset
          </p>
        </div>
        <div class="parrafoDesc">
          <p>
            <strong
              >In the following graphics we will see the distribution of scores
              for all 100 runs
            </strong>
          </p>
        </div>
        <div class="dataset">
          <img src="Fotos/good_acc_scores.png" alt="accuracy del modelo 2" />
          <img src="Fotos/good_rec_scores.png" alt="recall del modelo 2" />
        </div>
        <div class="dataset">
          <img src="Fotos/good_f1_scores.png" alt="f1 del modelo 2" />
          <img src="Fotos/good_pre_scores.png" alt="precision del modelo 2" />
        </div>
        <div class="parrafoDesc">
          <p>
            It is important to notice that the only metric we care about in this model is the <strong>recall</strong>
            which is the proportion of true positives amongst all entries we are sure are positive.
            On the contrary, the precision is also the proportion of true positives but amongst all entries the
            <strong>model</strong> says are positives. Since our classes are still umbalanced in our
            validation data (as it should be, since we must test on <strong>real data</strong>)
            the mayority of those positives predicted by the model, will be false positives, which will greatly
            surpass the amount of true positives. This is the reason why out precision is so low compared to our recall
          </p>
        </div>
        <div class="parrafoDesc">
          <p>
            We already know the accuracy is a weak metric against classification methods,
            since the accuracy is classless, this means that the metric doesn't see classes,
            it just sees the proportion of correctly guessed prediction over the total data.
            And the f1 score is a combination of recall and precision, and since we have good recall but bad precision,
            the f1 score will be dragged down by our low precision rating
          </p>
        </div>
      </div>
    </div>
  </body>
</html>
